{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f155410e",
   "metadata": {},
   "source": [
    "\n",
    "# Music Realism Scoring with WGAN-GP (Log-Mel, Codec Parity)\n",
    "\n",
    "This notebook trains a **WGAN-GP on real music only** (using **log-mel spectrograms**) and then uses the **discriminator** as a **realism score** for new tracks (AI vs. real).  \n",
    "It handles **codec parity** (WAV ↔ MP3 round-trip) to prevent shortcut learning, and fixes input shapes to **[1, 128, 256]** (channels, mels, frames).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6376480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Config (edit these paths & hyperparameters as you like) ===\n",
    "\n",
    "REAL_WAV_DIR = \"data/REAL_audio\"   # folder with *.wav (real music)\n",
    "AI_MP3_DIR   = \"data/AI_audio\"     # folder with *.mp3 (AI-generated music)\n",
    "\n",
    "# Audio & feature params\n",
    "SR            = 22050           # target sample rate\n",
    "WIN_SECS      = 10.0            # window length in seconds (we'll resize time to FRAMES)\n",
    "N_FFT         = 1024\n",
    "HOP           = 512             # gives ~430 frames for 10s, then we interpolate to FRAMES below\n",
    "N_MELS        = 128\n",
    "FMIN, FMAX    = 20.0, 8000.0\n",
    "FRAMES        = 256             # fixed time frames after interpolation (controls model size)\n",
    "TARGET_LUFS   = -14.0           # fallback to peak norm if pyloudnorm isn't available\n",
    "MP3_BITRATE   = \"192k\"          # codec parity target (requires ffmpeg, otherwise silently skipped)\n",
    "\n",
    "# Training params\n",
    "BATCH_SIZE    = 16\n",
    "EPOCHS        = 5               # bump as needed\n",
    "LR_G          = 2e-4\n",
    "LR_D          = 2e-4\n",
    "BETA1, BETA2  = 0.5, 0.9\n",
    "Z_DIM         = 128             # latent dim\n",
    "N_CRITIC      = 4               # WGAN-GP: D steps per G step\n",
    "LAMBDA_GP     = 10.0\n",
    "DEVICE        = \"cuda\"  # \"cuda\" if available, else \"cpu\" will be auto-detected below\n",
    "SEED          = 1337\n",
    "\n",
    "# Eval params\n",
    "MAX_EVAL_FILES_PER_CLASS = 100  # limit for fast demos; set None for all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cacb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu | pyloudnorm: True | ffmpeg: True | sklearn: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, math, random, shutil, tempfile, subprocess, warnings, glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "\n",
    "# Optional deps\n",
    "try:\n",
    "    import pyloudnorm as pyln\n",
    "    HAVE_PYL = True\n",
    "except Exception:\n",
    "    HAVE_PYL = False\n",
    "\n",
    "try:\n",
    "    import soundfile as sf\n",
    "    HAVE_SF = True\n",
    "except Exception:\n",
    "    HAVE_SF = False\n",
    "\n",
    "\n",
    "# sklearn is optional for metrics\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "    HAVE_SK = True\n",
    "except Exception:\n",
    "    HAVE_SK = False\n",
    "\n",
    "# Check FFmpeg availability (for MP3 round-trip)\n",
    "def _have_ffmpeg():\n",
    "    try:\n",
    "        subprocess.run([\"ffmpeg\", \"-version\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=False)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "HAVE_FFMPEG = _have_ffmpeg()\n",
    "\n",
    "# Device selection\n",
    "if DEVICE == \"cuda\" and not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "print(f\"Device: {DEVICE} | pyloudnorm: {HAVE_PYL} | ffmpeg: {HAVE_FFMPEG} | sklearn: {HAVE_SK}\")\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); \n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf52738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "try:\n",
    "    import soundfile as sf\n",
    "    HAVE_SF = True\n",
    "except Exception:\n",
    "    HAVE_SF = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde5de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_audio(path, sr=SR):\n",
    "    \"\"\"\n",
    "    Robust loader that avoids TorchCodec crashes:\n",
    "    1) For WAV/AIFF/FLAC: try soundfile (libsndfile).\n",
    "    2) For everything (incl. MP3/M4A): try librosa (audioread/ffmpeg).\n",
    "    3) Last resort: torchaudio.load.\n",
    "    Returns mono float tensor at target SR.\n",
    "    \"\"\"\n",
    "    ext = Path(path).suffix.lower()\n",
    "\n",
    "    # 1) Prefer soundfile for lossless containers\n",
    "    if HAVE_SF and ext in [\".wav\", \".aiff\", \".aif\", \".flac\", \".ogg\"]:\n",
    "        try:\n",
    "            y, file_sr = sf.read(str(path), dtype=\"float32\", always_2d=False)\n",
    "            if y.ndim == 2:\n",
    "                y = y.mean(axis=1)\n",
    "            wav_t = torch.from_numpy(y)\n",
    "            if file_sr != SR:\n",
    "                wav_t = torchaudio.functional.resample(wav_t.unsqueeze(0), file_sr, SR).squeeze(0)\n",
    "            return wav_t.contiguous()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) Librosa for anything (mp3, m4a, wav, etc.)\n",
    "    try:\n",
    "        y, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
    "        y = y.astype(np.float32, copy=False)\n",
    "        wav_t = torch.from_numpy(y)\n",
    "        if file_sr != SR:\n",
    "            wav_t = torchaudio.functional.resample(wav_t.unsqueeze(0), file_sr, SR).squeeze(0)\n",
    "        return wav_t.contiguous()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) Fallback to torchaudio (may require TorchCodec)\n",
    "    wav, file_sr = torchaudio.load(str(path))  # [C, T]\n",
    "    wav_t = wav.mean(dim=0)\n",
    "    if file_sr != SR:\n",
    "        wav_t = torchaudio.functional.resample(wav_t.unsqueeze(0), file_sr, SR).squeeze(0)\n",
    "    return wav_t.contiguous()\n",
    "\n",
    "def lufs_normalize(wav_t, sr=SR, target_lufs=TARGET_LUFS):\n",
    "    if HAVE_PYL:\n",
    "        y = wav_t.detach().cpu().numpy().astype(np.float32)\n",
    "        meter = pyln.Meter(sr)\n",
    "        try:\n",
    "            loud = meter.integrated_loudness(y)\n",
    "            gain_db = target_lufs - loud\n",
    "            gain = 10 ** (gain_db / 20.0)\n",
    "            y = np.clip(y * gain, -1.0, 1.0)\n",
    "            return torch.from_numpy(y)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback: simple peak normalization\n",
    "    peak = wav_t.abs().max().item()\n",
    "    if peak > 0:\n",
    "        wav_t = wav_t / peak\n",
    "    return wav_t\n",
    "\n",
    "def mp3_roundtrip(wav_t, sr=SR, bitrate=MP3_BITRATE):\n",
    "    if not HAVE_FFMPEG:\n",
    "        return wav_t\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as td:\n",
    "            wav_path = os.path.join(td, \"tmp.wav\")\n",
    "            mp3_path = os.path.join(td, \"tmp.mp3\")\n",
    "            torchaudio.save(wav_path, wav_t.unsqueeze(0), sr)\n",
    "            cmd = [\"ffmpeg\", \"-y\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "                   \"-i\", wav_path, \"-b:a\", bitrate, mp3_path]\n",
    "            res = subprocess.run(cmd, check=False)\n",
    "            if res.returncode != 0 or not os.path.exists(mp3_path):\n",
    "                # fall back gracefully\n",
    "                return wav_t\n",
    "            wav2, sr2 = torchaudio.load(mp3_path)\n",
    "            if sr2 != sr:\n",
    "                wav2 = torchaudio.functional.resample(wav2, sr2, sr)\n",
    "            return torch.mean(wav2, dim=0)\n",
    "    except Exception:\n",
    "        return wav_t\n",
    "\n",
    "# Log-mel transforms\n",
    "_mel = MelSpectrogram(\n",
    "    sample_rate=SR, n_fft=N_FFT, hop_length=HOP,\n",
    "    n_mels=N_MELS, f_min=FMIN, f_max=FMAX, center=True, power=2.0\n",
    ")\n",
    "_to_db = AmplitudeToDB(stype=\"power\")\n",
    "\n",
    "def to_logmel(wav_t):\n",
    "    # wav_t: [T] float32/float64\n",
    "    x = wav_t.unsqueeze(0)  # [1, T]\n",
    "    mel = _mel(x)           # [1, mels, frames]\n",
    "    mel_db = _to_db(mel)    # [1, mels, frames]\n",
    "    # min-max scale to [-1, 1] per-sample\n",
    "    m = mel_db.amin(dim=(1,2), keepdim=True)\n",
    "    M = mel_db.amax(dim=(1,2), keepdim=True)\n",
    "    mel_n = (mel_db - m) / (M - m + 1e-9)\n",
    "    mel_n = mel_n * 2.0 - 1.0\n",
    "    return mel_n   # [1, mels, frames] range ~ [-1,1]\n",
    "\n",
    "def fix_frames(spec_1mT, frames=FRAMES):\n",
    "    # spec_1mT: [1, mels, T]\n",
    "    T = spec_1mT.shape[-1]\n",
    "    if T == frames:\n",
    "        return spec_1mT\n",
    "    spec = F.interpolate(spec_1mT.unsqueeze(0), size=(N_MELS, frames), mode=\"bilinear\", align_corners=False)\n",
    "    return spec.squeeze(0)  # [1, mels, frames]\n",
    "\n",
    "def preprocess_file(path, codec_parity=False):\n",
    "    wav = load_audio(path, sr=SR)\n",
    "    if codec_parity:\n",
    "        wav = mp3_roundtrip(wav, sr=SR)\n",
    "    wav = lufs_normalize(wav, sr=SR, target_lufs=TARGET_LUFS)\n",
    "    # Extract a center window of ~WIN_SECS before mel (or pad if short)\n",
    "    N_SAMPLES = int(SR * WIN_SECS)\n",
    "    if wav.numel() < N_SAMPLES:\n",
    "        wav = F.pad(wav, (0, N_SAMPLES - wav.numel()))\n",
    "    else:\n",
    "        start = (wav.numel() - N_SAMPLES) // 2\n",
    "        wav = wav[start:start+N_SAMPLES]\n",
    "    mel = to_logmel(wav)          # [1, 128, T']\n",
    "    mel = fix_frames(mel, FRAMES) # [1, 128, 256]\n",
    "    return mel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a4664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found real WAV files: 2000 | AI MP3 files: 512\n",
      "Skipping 2 problematic files (showing first 10):\n",
      " - data\\REAL_audio\\jazz.00054.wav -> Error opening 'data\\\\REAL_audio\\\\jazz.00054.wav': Format not recognised.\n",
      " - data\\REAL_audio\\jazz.00054.wav -> Error opening 'data\\\\REAL_audio\\\\jazz.00054.wav': Format not recognised.\n",
      "Validated: 1998 usable files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class RealMelDataset(Dataset):\n",
    "    \"\"\"Real-only dataset. Each item is a fresh random 10s window from a file.\n",
    "    We do codec parity via MP3 round-trip so the discriminator can't cheat.\n",
    "    \"\"\"\n",
    "    def __init__(self, files, codec_parity=True):\n",
    "        self.files = files\n",
    "        self.codec_parity = codec_parity\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        # For variety, pick a random 10s segment BEFORE mel\n",
    "        wav = load_audio(path, sr=SR)\n",
    "        N_SAMPLES = int(SR * WIN_SECS)\n",
    "        if wav.numel() < N_SAMPLES:\n",
    "            wav = F.pad(wav, (0, N_SAMPLES - wav.numel()))\n",
    "        else:\n",
    "            max_start = wav.numel() - N_SAMPLES\n",
    "            start = int(torch.randint(0, max_start + 1, (1,)).item())\n",
    "            wav = wav[start:start+N_SAMPLES]\n",
    "        if self.codec_parity:\n",
    "            wav = mp3_roundtrip(wav, sr=SR)\n",
    "        wav = lufs_normalize(wav, sr=SR, target_lufs=TARGET_LUFS)\n",
    "        mel = to_logmel(wav)           # [1, 128, T']\n",
    "        mel = fix_frames(mel, FRAMES)  # [1, 128, 256]\n",
    "        return mel\n",
    "\n",
    "def list_audio_files(root, exts):\n",
    "    return sorted([p for ext in exts for p in Path(root).rglob(f\"*{ext}\")])\n",
    "\n",
    "real_files = list_audio_files(REAL_WAV_DIR, [\".wav\", \".WAV\"])\n",
    "ai_files   = list_audio_files(AI_MP3_DIR,   [\".mp3\", \".MP3\"])\n",
    "\n",
    "print(f\"Found real WAV files: {len(real_files)} | AI MP3 files: {len(ai_files)}\")\n",
    "\n",
    "def validate_real_files(files, sample_limit=None):\n",
    "    ok, bad = [], []\n",
    "    count = 0\n",
    "    for p in files:\n",
    "        try:\n",
    "            # light check: load a few seconds + mel (no parity here to be fast)\n",
    "            wav = load_audio(p, sr=SR)\n",
    "            if wav.numel() < int(SR * 1.0):  # require at least 1s audio\n",
    "                raise RuntimeError(\"too short\")\n",
    "            _ = to_logmel(wav[:int(SR * 2.0)])  # quick 2s mel test\n",
    "            ok.append(p)\n",
    "        except Exception as e:\n",
    "            bad.append((p, str(e)))\n",
    "        count += 1\n",
    "        if sample_limit and count >= sample_limit:\n",
    "            break\n",
    "    if bad:\n",
    "        print(f\"Skipping {len(bad)} problematic files (showing first 10):\")\n",
    "        for p, msg in bad[:10]:\n",
    "            print(\" -\", p, \"->\", msg)\n",
    "    print(f\"Validated: {len(ok)} usable files\")\n",
    "    return ok\n",
    "\n",
    "# Rebuild file list after validation\n",
    "real_files = validate_real_files(real_files)\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "# DataLoaders (SAFE SETTINGS for Windows/Jupyter)\n",
    "if len(real_files) > 0:\n",
    "    train_ds = RealMelDataset(real_files, codec_parity=True)\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,            # <= important\n",
    "        pin_memory=False,         # ok to False on CPU / notebook\n",
    "        persistent_workers=False, # <= important\n",
    "        drop_last=True,           # avoid last tiny batch oddities\n",
    "    )\n",
    "else:\n",
    "    train_ds, train_loader = None, None\n",
    "    warnings.warn(\"No real WAV files found. Please populate REAL_WAV_DIR to train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d09a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 256]) torch.float32 -0.9930947422981262 0.9921972751617432\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch.shape, batch.dtype, batch.min().item(), batch.max().item())\n",
    "# Expect ~ torch.Size([BATCH_SIZE, 1, 128, 256]) and values in [-1, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f32df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spectral_conv2d(in_ch, out_ch, k, s, p):\n",
    "    return nn.utils.spectral_norm(nn.Conv2d(in_ch, out_ch, k, s, p))\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"PatchGAN-style: accepts [B,1,128,256] and outputs [B,1] scalar scores via global pooling.\"\"\"\n",
    "    def __init__(self, use_spectral_norm=True):\n",
    "        super().__init__()\n",
    "        Conv = spectral_conv2d if use_spectral_norm else nn.Conv2d\n",
    "        chs = [1, 32, 64, 128, 256, 256]\n",
    "        self.net = nn.Sequential(\n",
    "            Conv(chs[0], chs[1],  (3,3), (2,2), (1,1)), nn.LeakyReLU(0.2, inplace=True),\n",
    "            Conv(chs[1], chs[2],  (3,3), (2,2), (1,1)), nn.LeakyReLU(0.2, inplace=True),\n",
    "            Conv(chs[2], chs[3],  (3,3), (2,2), (1,1)), nn.LeakyReLU(0.2, inplace=True),\n",
    "            Conv(chs[3], chs[4],  (3,3), (2,2), (1,1)), nn.LeakyReLU(0.2, inplace=True),\n",
    "            Conv(chs[4], chs[5],  (3,3), (2,2), (1,1)), nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.head = nn.Linear(chs[5], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B,1,128,256]\n",
    "        feat = self.net(x)                     # [B,C,h,w]\n",
    "        feat = feat.mean(dim=(2,3))            # global average pool -> [B,C]\n",
    "        out = self.head(feat)                  # [B,1]\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"DCGAN-ish generator to [1,128,256].\"\"\"\n",
    "    def __init__(self, z_dim=Z_DIM, base=256):\n",
    "        super().__init__()\n",
    "        # We'll map z -> [C0, 8, 16] then upsample to [1,128,256]\n",
    "        C0 = base\n",
    "        self.fc = nn.Linear(z_dim, C0*8*16)\n",
    "        def block(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "        self.up = nn.Sequential(\n",
    "            block(C0, 128),\n",
    "            block(128, 64),\n",
    "            block(64, 32),\n",
    "            block(32, 16),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(z.size(0), 256, 8, 16)  # [B,256,8,16]\n",
    "        x = self.up(x)                              # [B,1,128,256] (approximately after upsamples)\n",
    "        # If off by a few pixels due to stride math, interpolate to exact size\n",
    "        x = F.interpolate(x, size=(N_MELS, FRAMES), mode=\"bilinear\", align_corners=False)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e70922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def grad_penalty(D, real, fake, device):\n",
    "    B = real.size(0)\n",
    "    eps = torch.rand(B, 1, 1, 1, device=device)\n",
    "    x_hat = eps * real + (1 - eps) * fake\n",
    "    x_hat.requires_grad_(True)\n",
    "    d_hat = D(x_hat)\n",
    "    ones = torch.ones_like(d_hat, device=device)\n",
    "    grads = torch.autograd.grad(\n",
    "        outputs=d_hat, inputs=x_hat, grad_outputs=ones,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    gp = ((grads.view(B, -1).norm(2, dim=1) - 1.0) ** 2).mean()\n",
    "    return gp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_wgan_gp(train_loader, epochs=EPOCHS, z_dim=Z_DIM, device=DEVICE):\n",
    "    if train_loader is None:\n",
    "        print(\"No training data. Populate REAL_WAV_DIR with .wav files and rerun.\")\n",
    "        return None, None\n",
    "\n",
    "    D = Discriminator(use_spectral_norm=True).to(device)\n",
    "    G = Generator(z_dim=z_dim).to(device)\n",
    "\n",
    "    optD = torch.optim.Adam(D.parameters(), lr=LR_D, betas=(BETA1, BETA2))\n",
    "    optG = torch.optim.Adam(G.parameters(), lr=LR_G, betas=(BETA1, BETA2))\n",
    "\n",
    "    global_step = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=True)\n",
    "        for mel in pbar:\n",
    "            mel = mel.to(device)\n",
    "            B = mel.size(0)\n",
    "\n",
    "            # ===== Train D (N_CRITIC steps) =====\n",
    "            loss_D_val = 0.0\n",
    "            for _ in range(N_CRITIC):\n",
    "                z = torch.randn(B, z_dim, device=device)\n",
    "                fake = G(z).detach()\n",
    "                d_real = D(mel).mean()\n",
    "                d_fake = D(fake).mean()\n",
    "                gp = grad_penalty(D, mel, fake, device)\n",
    "                loss_D = (d_fake - d_real) + LAMBDA_GP * gp\n",
    "\n",
    "                optD.zero_grad(set_to_none=True)\n",
    "                loss_D.backward()\n",
    "                optD.step()\n",
    "                loss_D_val = loss_D.item()\n",
    "\n",
    "            # ===== Train G (1 step) =====\n",
    "            z = torch.randn(B, z_dim, device=device)\n",
    "            fake = G(z)\n",
    "            loss_G = -D(fake).mean()\n",
    "            optG.zero_grad(set_to_none=True)\n",
    "            loss_G.backward()\n",
    "            optG.step()\n",
    "\n",
    "            # tqdm stats\n",
    "            pbar.set_postfix({\n",
    "                \"D\": f\"{loss_D_val:.3f}\",\n",
    "                \"G\": f\"{loss_G.item():.3f}\",\n",
    "                \"d_real\": f\"{d_real.item():.3f}\",\n",
    "                \"d_fake\": f\"{d_fake.item():.3f}\"\n",
    "            })\n",
    "            global_step += 1\n",
    "\n",
    "    return G, D\n",
    "# Quick dry-run (skips if no data)\n",
    "# G, D = train_wgan_gp(train_loader, epochs=1)\n",
    "# torch.save(D.state_dict(), \"D.pth\"); torch.save(G.state_dict(), \"G.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02fadead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def score_windows_with_D(D, mels, device=DEVICE):\n",
    "    D.eval()\n",
    "    scores = []\n",
    "    for i in range(0, len(mels), 16):\n",
    "        batch = torch.stack(mels[i:i+16], dim=0).to(device)  # [B,1,128,256]\n",
    "        s = D(batch).squeeze(1).detach().cpu().numpy()\n",
    "        scores.extend(s.tolist())\n",
    "    return float(np.mean(scores)), scores\n",
    "\n",
    "def slice_track_to_mels(path, codec_parity_for_real=False, step_secs=10.0):\n",
    "    \"\"\"Return list of [1,128,256] mel windows for an entire track.\n",
    "    - For real WAVs, pass codec_parity_for_real=True to round-trip MP3.\n",
    "    - For AI MP3s, leave False (already MP3).\n",
    "    \"\"\"\n",
    "    wav = load_audio(path, sr=SR)\n",
    "    if codec_parity_for_real:\n",
    "        wav = mp3_roundtrip(wav, sr=SR)\n",
    "    wav = lufs_normalize(wav, sr=SR, target_lufs=TARGET_LUFS)\n",
    "\n",
    "    N = int(SR * WIN_SECS)\n",
    "    step = int(SR * step_secs)\n",
    "    if wav.numel() < N:\n",
    "        wav = F.pad(wav, (0, N - wav.numel()))\n",
    "\n",
    "    mels = []\n",
    "    for start in range(0, max(1, wav.numel() - N + 1), step):\n",
    "        seg = wav[start:start+N]\n",
    "        mel = to_logmel(seg)\n",
    "        mel = fix_frames(mel, FRAMES)\n",
    "        mels.append(mel)\n",
    "    return mels  # list of [1,128,256]\n",
    "\n",
    "def score_folder(D, folder, exts, real_folder=False, max_files=None):\n",
    "    files = sorted([p for ext in exts for p in Path(folder).rglob(f\"*{ext}\")])\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    kept_files, kept_scores = [], []\n",
    "    for p in files:\n",
    "        try:\n",
    "            codec_parity = real_folder  # True for real WAVs, False for AI MP3s\n",
    "            mels = slice_track_to_mels(p, codec_parity_for_real=codec_parity, step_secs=WIN_SECS)\n",
    "            if not mels:\n",
    "                continue\n",
    "            mean_s, _ = score_windows_with_D(D, mels)\n",
    "            kept_files.append(p)\n",
    "            kept_scores.append(mean_s)\n",
    "        except Exception as e:\n",
    "            # Skip problematic file; keep evaluation running\n",
    "            print(f\"[skip] {p} -> {e}\")\n",
    "            continue\n",
    "\n",
    "    return kept_files, np.array(kept_scores, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7a0f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_discriminator(D, real_dir=REAL_WAV_DIR, ai_dir=AI_MP3_DIR, max_files=MAX_EVAL_FILES_PER_CLASS):\n",
    "    if not HAVE_SK:\n",
    "        print(\"scikit-learn not found — skipping ROC-AUC/PR-AUC. You can 'pip install scikit-learn' and rerun.\")\n",
    "        return None\n",
    "\n",
    "    real_files, real_scores = score_folder(D, real_dir, [\".wav\", \".WAV\"], real_folder=True, max_files=max_files)\n",
    "    ai_files,   ai_scores   = score_folder(D, ai_dir,   [\".mp3\", \".MP3\"], real_folder=False, max_files=max_files)\n",
    "\n",
    "    y_true = np.array([1]*len(real_scores) + [0]*len(ai_scores), dtype=np.int32)\n",
    "    y_pred = np.concatenate([real_scores, ai_scores], axis=0)\n",
    "\n",
    "    roc = roc_auc_score(y_true, y_pred)\n",
    "    pr  = average_precision_score(y_true, y_pred)\n",
    "    print(f\"ROC-AUC: {roc:.4f} | PR-AUC: {pr:.4f}\")\n",
    "    return {\n",
    "        \"roc_auc\": float(roc),\n",
    "        \"pr_auc\": float(pr),\n",
    "        \"real_scores\": real_scores,\n",
    "        \"ai_scores\": ai_scores,\n",
    "        \"real_files\": [str(p) for p in real_files],\n",
    "        \"ai_files\": [str(p) for p in ai_files],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20bffa2",
   "metadata": {},
   "source": [
    "\n",
    "## Quickstart\n",
    "\n",
    "1. Put your data here (or change the config):\n",
    "   - `data/real_wav/**.wav`\n",
    "   - `data/ai_mp3/**.mp3`\n",
    "\n",
    "2. Run training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e71e79ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 124/124 [05:49<00:00,  2.82s/it, D=-10.361, G=81.013, d_real=-73.901, d_fake=-84.466]\n",
      "Epoch 2/5: 100%|██████████| 124/124 [03:43<00:00,  1.80s/it, D=-9.126, G=10.613, d_real=-1.455, d_fake=-10.982]    \n",
      "Epoch 3/5: 100%|██████████| 124/124 [03:16<00:00,  1.58s/it, D=-7.015, G=16.547, d_real=-2.427, d_fake=-9.511]     \n",
      "Epoch 4/5: 100%|██████████| 124/124 [03:09<00:00,  1.53s/it, D=-11.593, G=-3.206, d_real=8.712, d_fake=-3.721]      \n",
      "Epoch 5/5: 100%|██████████| 124/124 [03:25<00:00,  1.66s/it, D=-11.495, G=18.409, d_real=-11.392, d_fake=-22.922]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved D.pth and G.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the GAN on REAL only (WGAN-GP). Increase EPOCHS later.\n",
    "G, D = train_wgan_gp(train_loader, epochs=EPOCHS)\n",
    "\n",
    "# Save checkpoints\n",
    "if D is not None and G is not None:\n",
    "    torch.save(D.state_dict(), \"D.pth\")\n",
    "    torch.save(G.state_dict(), \"G.pth\")\n",
    "    print(\"Saved D.pth and G.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a356a",
   "metadata": {},
   "source": [
    "\n",
    "3. Score folders and compute metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f649a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.1468 | PR-AUC: 0.3437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'D' in globals() and D is not None:\n",
    "    _ = evaluate_discriminator(D, real_dir=REAL_WAV_DIR, ai_dir=AI_MP3_DIR, max_files=MAX_EVAL_FILES_PER_CLASS)\n",
    "else:\n",
    "    print(\"Train (or load) a Discriminator first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e587738",
   "metadata": {},
   "source": [
    "\n",
    "### Load Discriminator later & score single files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d08469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean realism score: -14.58976697921753\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_discriminator(path=\"D.pth\", device=DEVICE):\n",
    "    D = Discriminator(use_spectral_norm=True).to(device)\n",
    "    sd = torch.load(path, map_location=device)\n",
    "    D.load_state_dict(sd)\n",
    "    D.eval()\n",
    "    return D\n",
    "\n",
    "# Example single-file scoring (edit the paths):\n",
    "D = load_discriminator(\"D.pth\")\n",
    "mels = slice_track_to_mels(\"data/AI_audio/-0Gj8-vB1q4_1.mp3\", codec_parity_for_real=False, step_secs=WIN_SECS)\n",
    "mean_score, window_scores = score_windows_with_D(D, mels)\n",
    "print(\"Mean realism score:\", mean_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9816f3d3",
   "metadata": {},
   "source": [
    "\n",
    "## Notes & Tips\n",
    "\n",
    "- **Codec parity matters**: we round-trip real WAVs through MP3 (192 kbps) during training and when *scoring* real files.  \n",
    "  If `ffmpeg` isn't available, the notebook will silently skip parity (you can install ffmpeg to enable it).\n",
    "\n",
    "- **Loudness normalization**: LUFS if `pyloudnorm` is installed, else peak-normalization fallback.\n",
    "\n",
    "- **Input shape fixed**: mel specs resized to `[1, 128, 256]`. You can increase `FRAMES` (e.g., 512) if your GPU has room.\n",
    "\n",
    "- **Stability**: We use **WGAN-GP** and **spectral norm** on the discriminator.\n",
    "\n",
    "- **Sanity check**: Before full training, try a few batches to ensure losses move and `d_real > d_fake` early on.\n",
    "\n",
    "- **Evaluation**: The **mean discriminator score** per track is your realism score. With scikit-learn installed, we report **ROC-AUC** and **PR-AUC**.\n",
    "\n",
    "- **Next steps**: try **PCEN** instead of dB, add light augmentations, or move to longer windows, then compare metrics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
